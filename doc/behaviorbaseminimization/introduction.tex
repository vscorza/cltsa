\section{Introduction}
%specifications are hard to write properly and stay unrealizable for a long time


Requirements are naturally split between goals the system-to-be is expected to achieve and
assumptions that the system-to-be can rely on to fulfill its goals ~\cite{Jackson:1995,Letier:2002}. The question to be asked then is one of realizability: Is it possible to build a system that can monitor its environment and react through its capabilities in order to guarantee its goals as long as the environment fulfils the assumptions?

At early stages specifications are usually unrealizable ~\cite{Letier:2002}. There can be multiple causes for unrealizability including lack of monitorability and controllability, and over-idealization of goals and assumptions. Goals in their first formulations tend to be stronger than what can be reasonably required and assumptions tend to be too weak, failing to rule out exceptional circumstances that the system cannot deal with ~\cite{vanLamsweerde:2000}. 

Unfortunately, the cause for unrealizability tends to be the result of a combination of issues and is not easy to detect or understand. Providing engineers feedback that allows them to understand the cause for unrealizability is highly desired if specifications are to be evolved into realizable ones that can then be implemented. 

In general the process of producing a running system from a specification is manual and laborious. However, in some settings this process can be done automatically, ensuring a correct by construction system. This is the case for systems studied by supervisory control ~\cite{ramadge:1989}, FOND planning ~\cite{daniele:2000} and controller synthesis ~\cite{Maoz:2014,Bloem:2012}. 
In these settings, given a specification, an algorithm produces a strategy (that can be encoded as an automaton) that by monitoring and acting over its environment can guarantee the goals as long as the environment satisfies the assumptions. 

Synthesis algorithms only produce a system strategy if the original specification is realizable. 
When the specification is unrealizable, the engineer is left with the onerous task of understanding why no such strategy exists and, only after that, with the task of changing the specification.
\emph{In this paper, we propose a novel technique that provides feedback on unrealizable specifications}. 

Techniques for providing feedback on unrealizability have been proposed in ~\cite{DBLP:conf/fmcad/KonighoferHB09, DBLP:journals/scp/Schuppan12,DBLP:conf/fmcad/AlurMT13},
these assume that the specification is given in an expressive subset of Linear Temporal Logic (LTL) formulae, called \gr, and return a minimal subset of these that is still unrealizable. In other words, and in the spirit of unsatisfiable cores~\cite{Torlak:2008}, the technique produces a minimal subset of the original formulae that is still unrealizable. The intention is to allow engineers to focus on a portion of the original specification to identify the causes for unrealizability. 

In this paper we propose an alternative and potentially complementary technique for providing feedback on unrealizability. The technique \textit{differs} from existing ones in two ways. First and foremost, the approach minimizes allowable behavior while preserving unrealizability. The result is a model that exhibits a minimal representation of the original behavior while preserving the unrealizability causes present in the initial specification. In contrast, in existing approaches the reduced number of formulae results in a model that allows more behavior than originally specified. The second difference is that the approach presented herein assumes an automata-based description of the environment rather than an LTL specification. Automata-based specifications of the environment (e.g., labeled transition systems~\cite{Keller:1976}, statecharts~\cite{Harel:1987}, and process algebra~\cite{Milner:1982,Hoare:1983}) are common approaches to environment description in software engineering literature. There are a variety of software engineering tasks that have been approached using synthesis and automata-based descriptions (e.g,~\cite{Letier:2013:RMS,DIppolito:2013,Pistore:2004:PMW}). %Heaven:2009:GDA

The technique we present minimizes behavior  while preserving unrealizability. \textit{What does this mean?} A specification determines a game in which one player, the environment, tries to satisfy the assumptions while preventing the other player, the system-to-be, from achieving its goals. If the specification is unrealizable, it means that the environment has a playing strategy that always beats its opponent. In other words, no matter what the system-to-be does, it cannot achieve its goals. We refer to a minimization that preserves unrealizability as a process that produces a new model that has less behavior and for which the winning strategy of the environment also works in the original specification. This allows engineers to focus on the behavior of the original specification that causes unrealizability. 

%The technique has also the potential to complement existing techniques that assume a specification only in LTL form and that work by performing a declarative, rather than a behavior-based, minimization.

The paper is structured as follows. We first provide a motivating example as an informal overview of the proposed technique, we then present some preliminary definitions, namely to define formally a control problem and the notion of realizability, and then go on to define minimization and non-realizability preservation. In Section~\ref{sect:solution} we present the minimization algorithm and then discuss our way of validating the technique. We finally proceed with a discussion on related work and conclusions.