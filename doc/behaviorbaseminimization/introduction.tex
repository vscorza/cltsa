\section{Introduction}\label{sec:introduction}
%specifications are hard to write properly and stay unrealizable for a long time


Requirements are naturally split between goals the system-to-be is expected to achieve and
assumptions that the system-to-be can rely on to fulfill its goals ~\cite{Jackson:1995,Letier:2002}. The question to be asked then is one of realizability: Is it possible to build a system that can monitor its environment and react through its capabilities in order to guarantee its goals as long as the environment fulfils the assumptions?

At early stages specifications are usually unrealizable ~\cite{Letier:2002}. There can be multiple causes for unrealizability including lack of monitorability and controllability, and over-idealization of goals and assumptions. Goals in their first formulations tend to be stronger than what can be reasonably required and assumptions tend to be too weak, failing to rule out exceptional circumstances that the system cannot deal with ~\cite{vanLamsweerde:2000}. 

Unfortunately, the cause for unrealizability tends to be the result of a combination of issues and is not easy to detect or understand. Providing engineers feedback that allows them to understand the cause for unrealizability is highly desired if specifications are to be evolved into realizable ones that can then be implemented. 

In general the process of producing a running system from a specification is manual and laborious. However, in some settings this process can be done automatically, ensuring a correct by construction system. This is the case for systems studied by supervisory control ~\cite{ramadge:1989}, FOND planning ~\cite{daniele:2000} and controller synthesis ~\cite{Maoz:2014,Bloem:2012}. 
In these settings, given a specification, an algorithm produces a strategy (that can be encoded as an automaton) that by monitoring and acting over its environment can guarantee the goals as long as the environment satisfies the assumptions. 

Synthesis algorithms only produce a system strategy if the original specification is realizable. 
When the specification is unrealizable, the engineer is left with the onerous task of understanding why no such strategy exists and, only after that, with the task of changing the specification.
\emph{In this paper, we propose a novel technique that provides feedback on unrealizable specifications over explicit models}. 

Techniques for providing feedback on unrealizability have been proposed in ~\cite{DBLP:conf/fmcad/KonighoferHB09, DBLP:journals/scp/Schuppan12,DBLP:conf/fmcad/AlurMT13},
these assume that the specification is given in an expressive subset of Linear Temporal Logic (LTL) formulae, called \gr, and return a minimal subset of these that is still unrealizable. In other words, and in the spirit of unsatisfiable cores~\cite{Torlak:2008}, the technique produces a minimal subset of the original environmental formulae that is still unrealizable. The intention is to allow engineers to focus on a portion of the original specification to identify the causes for unrealizability. ~\cite{DBLP:conf/fmcad/KonighoferHB09} also provides a counterstrategy over which either a countertrace can be produced as a witness for unrealizability or a game can be interactively played with the user in order to aid in understanding the cause of the problem. In ~\cite{DBLP:conf/sigsoft/KuventMR17} a simplification of the counterstrategy in terms of attractors and cycles is provided, going further in the simplification of the cause by providing only relevant information in terms of valuation changes, this is also the starting point of other techniques, such as ~\cite{maoz2019symbolic}, where ~\cite{DBLP:conf/sigsoft/KuventMR17} output is used to repair the initial GR(1) specification.

In this paper we propose an alternative and complementary technique for providing feedback on unrealizability. In \textit{differs} from existing techniques in two ways. First and foremost, it can work both with explicit and symbolic specifications. To the best of our knowledge, no previous work approached the problem of diagnosing unrealizability over explicit models.  When working with symbolic definitions our tool creates an automaton representation of the plant by translating an OBDD to a CLTS. Automata-based specifications of the environment (e.g., labeled transition systems~\cite{Keller:1976}, statecharts~\cite{Harel:1987}, and process algebra~\cite{Milner:1982,Hoare:1983}) are common approaches to environment description in software engineering literature. There are a variety of software engineering tasks that have been approached using synthesis and automata-based descriptions (e.g,~\cite{Letier:2013:RMS,DIppolito:2013,Pistore:2004:PMW}). The explicit nature of our output enables the use of the minimization when building a test suite or test bench. The second difference is that the approach minimizes the initial plant, resulting in an explicit model that exhibits a minimal representation of the original behavior, in contrast with existing approaches, where reducing the number of formulae results in a model that allows more behavior than originally specified. 

\textit{What does it mean to minimize behavior while preserving unrealizability this mean?} A specification determines a game in which one player, the environment, tries to satisfy the assumptions while preventing the other player, the system-to-be, from achieving its goals. If the specification is unrealizable, it means that the environment has a playing strategy that always beats its opponent. In other words, no matter what the system-to-be does, it cannot achieve its goals. We refer to a minimization that preserves unrealizability as a process that produces a new model that has less behavior and for which the winning strategy of the environment also works in the original specification. This allows engineers to focus on the behavior of the original specification that causes unrealizability. The importance of the technique lies not in how much of the general plant is removed but on the benefits it presents during diagnosis, because a smaller plant will in turn produce smaller, simpler traces for the user to explore, analyze and use as guide towards the understanding of the underlying non realizability cause.



%The technique has also the potential to complement existing techniques that assume a specification only in LTL form and that work by performing a declarative, rather than a behavior-based, minimization.

The paper is structured as follows. We first provide a motivating example as an informal overview of the proposed technique, we then present some preliminary definitions, namely to define formally a control problem and the notion of realizability, and then go on to define minimization and non-realizability preservation. In Section~\ref{sect:solution} we present the minimization algorithm and then discuss our way of validating the technique. We finally proceed with a discussion on related work and conclusions.